#!/usr/bin/env python3
"""
Classificador Melhorado de Espinhas DendrÃ­ticas
Baseado em critÃ©rios morfolÃ³gicos da literatura e classificaÃ§Ãµes manuais
"""

import pandas as pd
import numpy as np
from pathlib import Path
import json
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

class ImprovedSpineClassifier:
    """Classificador de espinhas baseado em features morfolÃ³gicas"""
    
    def __init__(self):
        self.model = None
        self.feature_names = []
        self.class_names = ['mushroom', 'thin', 'stubby', 'filopodia', 'double_head', 'unclassified']
        
        # CritÃ©rios baseados na literatura (Pchitskaya & Bezprozvanny, 2020)
        self.literature_criteria = {
            'mushroom': {
                'min_head_diameter': 0.6,  # Î¼m
                'min_head_neck_ratio': 1.5,
                'description': 'CabeÃ§a grande e pescoÃ§o estreito'
            },
            'thin': {
                'min_length': 0.7,  # Î¼m
                'max_head_diameter': 0.6,  # Î¼m
                'description': 'PescoÃ§o longo e cabeÃ§a pequena'
            },
            'stubby': {
                'max_length': 0.5,  # Î¼m
                'description': 'Sem pescoÃ§o definido, cabeÃ§a pequena'
            },
            'filopodia': {
                'min_length': 2.0,  # Î¼m
                'description': 'ExtensÃ£o longa sem cabeÃ§a definida'
            },
            'double_head': {
                'description': 'Duas cabeÃ§as em um pescoÃ§o'
            }
        }
    
    def extract_morphological_features(self, spine_data):
        """Extrair features morfolÃ³gicas das espinhas"""
        features = []
        
        for _, spine in spine_data.iterrows():
            # Calcular comprimento
            length_pixels = np.sqrt((spine['tip_x'] - spine['base_x'])**2 + 
                                  (spine['tip_y'] - spine['base_y'])**2)
            length_um = length_pixels * 0.1  # Assumindo 0.1 Î¼m/pixel
            
            # Features bÃ¡sicas
            feature_vector = [
                length_um,  # Comprimento em Î¼m
                length_pixels,  # Comprimento em pixels
                spine['confidence'],  # ConfianÃ§a do detector
                # Adicionar mais features conforme necessÃ¡rio
            ]
            
            features.append(feature_vector)
        
        return np.array(features)
    
    def classify_by_literature_criteria(self, spine_data):
        """Classificar espinhas usando critÃ©rios da literatura"""
        classifications = []
        
        for _, spine in spine_data.iterrows():
            # Calcular comprimento
            length_pixels = np.sqrt((spine['tip_x'] - spine['base_x'])**2 + 
                                  (spine['tip_y'] - spine['base_y'])**2)
            length_um = length_pixels * 0.1
            
            # Aplicar critÃ©rios da literatura
            if length_um >= 2.0:
                classification = 'filopodia'
            elif length_um <= 0.5:
                classification = 'stubby'
            elif length_um >= 0.7:
                # Para thin vs mushroom, precisamos de mais features
                # Por enquanto, usar heurÃ­stica simples
                if spine['confidence'] > 0.7:
                    classification = 'mushroom'
                else:
                    classification = 'thin'
            else:
                classification = 'unclassified'
            
            classifications.append(classification)
        
        return classifications
    
    def train_with_manual_data(self, training_data):
        """Treinar modelo com dados manuais"""
        print("ðŸ§  Treinando classificador com dados manuais...")
        
        # Extrair features
        X = self.extract_morphological_features(training_data)
        y = training_data['manual_classification'].values
        
        # Definir nomes das features
        self.feature_names = ['length_um', 'length_pixels', 'confidence']
        
        # Treinar modelo
        self.model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.model.fit(X, y)
        
        # Avaliar performance
        y_pred = self.model.predict(X)
        
        # Obter classes Ãºnicas nos dados
        unique_classes = np.unique(np.concatenate([y, y_pred]))
        
        print("\nðŸ“Š Performance do Modelo Treinado:")
        print(classification_report(y, y_pred, labels=unique_classes, target_names=unique_classes))
        
        # Matriz de confusÃ£o
        cm = confusion_matrix(y, y_pred, labels=unique_classes)
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=unique_classes, yticklabels=unique_classes)
        plt.title('Matriz de ConfusÃ£o - Classificador Treinado')
        plt.xlabel('PrediÃ§Ã£o')
        plt.ylabel('Real')
        plt.tight_layout()
        
        # Salvar figura
        output_path = Path('/Users/erik/Desktop/Sinapses/TIFFS/_Working/confusion_matrix_trained.png')
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"ðŸ“Š Matriz de confusÃ£o salva em: {output_path}")
        
        return self.model
    
    def classify_spines(self, spine_data, method='hybrid'):
        """Classificar espinhas usando mÃ©todo especificado"""
        if method == 'literature':
            return self.classify_by_literature_criteria(spine_data)
        elif method == 'ml' and self.model is not None:
            X = self.extract_morphological_features(spine_data)
            return self.model.predict(X)
        elif method == 'hybrid':
            # Combinar literatura + ML
            lit_classifications = self.classify_by_literature_criteria(spine_data)
            
            if self.model is not None:
                X = self.extract_morphological_features(spine_data)
                ml_classifications = self.model.predict(X)
                
                # Combinar resultados (literatura tem prioridade para casos claros)
                hybrid_classifications = []
                for i, (lit, ml) in enumerate(zip(lit_classifications, ml_classifications)):
                    if lit in ['filopodia', 'stubby']:  # CritÃ©rios claros da literatura
                        hybrid_classifications.append(lit)
                    else:
                        hybrid_classifications.append(ml)
                
                return hybrid_classifications
            else:
                return lit_classifications
        else:
            raise ValueError(f"MÃ©todo '{method}' nÃ£o suportado")
    
    def evaluate_performance(self, test_data, method='hybrid'):
        """Avaliar performance do classificador"""
        predictions = self.classify_spines(test_data, method=method)
        actual = test_data['manual_classification'].values
        
        # Calcular mÃ©tricas
        accuracy = np.mean(predictions == actual) * 100
        
        print(f"\nðŸ“ˆ Performance do MÃ©todo '{method}':")
        print(f"PrecisÃ£o Geral: {accuracy:.1f}%")
        
        # RelatÃ³rio detalhado
        unique_classes = np.unique(np.concatenate([actual, predictions]))
        print("\nRelatÃ³rio de ClassificaÃ§Ã£o:")
        print(classification_report(actual, predictions, labels=unique_classes, target_names=unique_classes))
        
        return accuracy, predictions

def load_training_data():
    """Carregar dados de treinamento"""
    training_path = Path('/Users/erik/Desktop/Sinapses/TIFFS/_Working/Spines_Reorg/Results/manual_classifications_training.csv')
    
    if not training_path.exists():
        print("âŒ Arquivo de treinamento nÃ£o encontrado!")
        return None
    
    df = pd.read_csv(training_path)
    print(f"ðŸ“¥ Carregados {len(df)} exemplos de treinamento")
    
    return df

def load_all_spines_data():
    """Carregar todos os dados de espinhas"""
    results_dir = Path('/Users/erik/Desktop/Sinapses/TIFFS/_Working/Spines_Reorg/Results/ASD16/CRISPRa')
    
    all_spines = []
    for csv_file in results_dir.glob('*_per_spine.csv'):
        df = pd.read_csv(csv_file)
        all_spines.append(df)
    
    if not all_spines:
        print("âŒ Nenhum arquivo de espinhas encontrado!")
        return None
    
    combined_df = pd.concat(all_spines, ignore_index=True)
    print(f"ðŸ“¥ Carregadas {len(combined_df)} espinhas totais")
    
    return combined_df

def main():
    """FunÃ§Ã£o principal"""
    print("ðŸ”¬ Classificador Melhorado de Espinhas DendrÃ­ticas")
    print("="*60)
    
    # Carregar dados
    training_data = load_training_data()
    if training_data is None:
        return
    
    all_spines = load_all_spines_data()
    if all_spines is None:
        return
    
    # Criar classificador
    classifier = ImprovedSpineClassifier()
    
    # Treinar com dados manuais
    classifier.train_with_manual_data(training_data)
    
    # Avaliar diferentes mÃ©todos
    print("\n" + "="*60)
    print("ðŸ“Š AVALIAÃ‡ÃƒO DE DIFERENTES MÃ‰TODOS")
    print("="*60)
    
    # MÃ©todo 1: Apenas critÃ©rios da literatura
    print("\n1ï¸âƒ£ MÃ©todo: CritÃ©rios da Literatura")
    lit_accuracy, lit_predictions = classifier.evaluate_performance(training_data, method='literature')
    
    # MÃ©todo 2: Machine Learning
    print("\n2ï¸âƒ£ MÃ©todo: Machine Learning")
    ml_accuracy, ml_predictions = classifier.evaluate_performance(training_data, method='ml')
    
    # MÃ©todo 3: HÃ­brido
    print("\n3ï¸âƒ£ MÃ©todo: HÃ­brido (Literatura + ML)")
    hybrid_accuracy, hybrid_predictions = classifier.evaluate_performance(training_data, method='hybrid')
    
    # Resumo
    print("\n" + "="*60)
    print("ðŸ“ˆ RESUMO DE PERFORMANCE")
    print("="*60)
    print(f"CritÃ©rios da Literatura: {lit_accuracy:.1f}%")
    print(f"Machine Learning:       {ml_accuracy:.1f}%")
    print(f"MÃ©todo HÃ­brido:         {hybrid_accuracy:.1f}%")
    
    # Aplicar melhor mÃ©todo a todas as espinhas
    best_method = 'hybrid' if hybrid_accuracy >= max(lit_accuracy, ml_accuracy) else 'ml' if ml_accuracy >= lit_accuracy else 'literature'
    
    print(f"\nðŸŽ¯ Melhor mÃ©todo: {best_method} ({max(lit_accuracy, ml_accuracy, hybrid_accuracy):.1f}%)")
    
    # Classificar todas as espinhas
    print(f"\nðŸ”„ Aplicando melhor mÃ©todo a todas as {len(all_spines)} espinhas...")
    all_predictions = classifier.classify_spines(all_spines, method=best_method)
    
    # Atualizar dados
    all_spines['improved_type'] = all_predictions
    all_spines['classification_method'] = best_method
    
    # Salvar resultados
    output_path = Path('/Users/erik/Desktop/Sinapses/TIFFS/_Working/Spines_Reorg/Results/improved_classifications.csv')
    all_spines.to_csv(output_path, index=False)
    
    print(f"âœ… Resultados salvos em: {output_path}")
    
    # EstatÃ­sticas finais
    print(f"\nðŸ“Š DistribuiÃ§Ã£o Final das ClassificaÃ§Ãµes:")
    final_counts = pd.Series(all_predictions).value_counts()
    for class_name, count in final_counts.items():
        percentage = count / len(all_predictions) * 100
        print(f"  {class_name}: {count} ({percentage:.1f}%)")
    
    print("\nâœ… ClassificaÃ§Ã£o melhorada concluÃ­da!")

if __name__ == "__main__":
    main()
